{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1759,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0028425241614553724,
      "grad_norm": 126.82986450195312,
      "learning_rate": 5e-06,
      "loss": 10.2593,
      "step": 5
    },
    {
      "epoch": 0.005685048322910745,
      "grad_norm": 144.8986053466797,
      "learning_rate": 1e-05,
      "loss": 9.2072,
      "step": 10
    },
    {
      "epoch": 0.008527572484366117,
      "grad_norm": 122.41828155517578,
      "learning_rate": 1.5e-05,
      "loss": 6.008,
      "step": 15
    },
    {
      "epoch": 0.01137009664582149,
      "grad_norm": 70.04827117919922,
      "learning_rate": 2e-05,
      "loss": 2.3145,
      "step": 20
    },
    {
      "epoch": 0.014212620807276862,
      "grad_norm": 2.1309852600097656,
      "learning_rate": 2.5e-05,
      "loss": 0.6198,
      "step": 25
    },
    {
      "epoch": 0.017055144968732235,
      "grad_norm": 5.432163715362549,
      "learning_rate": 3e-05,
      "loss": 0.4147,
      "step": 30
    },
    {
      "epoch": 0.019897669130187607,
      "grad_norm": 0.7207242846488953,
      "learning_rate": 3.5e-05,
      "loss": 0.153,
      "step": 35
    },
    {
      "epoch": 0.02274019329164298,
      "grad_norm": 2.3239824771881104,
      "learning_rate": 4e-05,
      "loss": 0.2417,
      "step": 40
    },
    {
      "epoch": 0.025582717453098352,
      "grad_norm": 0.4211222529411316,
      "learning_rate": 4.5e-05,
      "loss": 0.1809,
      "step": 45
    },
    {
      "epoch": 0.028425241614553724,
      "grad_norm": 1.741568922996521,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 50
    },
    {
      "epoch": 0.03126776577600909,
      "grad_norm": 2.4583191871643066,
      "learning_rate": 4.985371562317145e-05,
      "loss": 0.3426,
      "step": 55
    },
    {
      "epoch": 0.03411028993746447,
      "grad_norm": 0.2867414355278015,
      "learning_rate": 4.970743124634289e-05,
      "loss": 0.1855,
      "step": 60
    },
    {
      "epoch": 0.03695281409891984,
      "grad_norm": 0.2330704629421234,
      "learning_rate": 4.9561146869514335e-05,
      "loss": 0.0974,
      "step": 65
    },
    {
      "epoch": 0.039795338260375214,
      "grad_norm": 1.8824472427368164,
      "learning_rate": 4.941486249268578e-05,
      "loss": 0.121,
      "step": 70
    },
    {
      "epoch": 0.04263786242183058,
      "grad_norm": 0.1988999843597412,
      "learning_rate": 4.9268578115857225e-05,
      "loss": 0.2138,
      "step": 75
    },
    {
      "epoch": 0.04548038658328596,
      "grad_norm": 1.9643093347549438,
      "learning_rate": 4.9122293739028674e-05,
      "loss": 0.1406,
      "step": 80
    },
    {
      "epoch": 0.04832291074474133,
      "grad_norm": 0.10332329571247101,
      "learning_rate": 4.897600936220012e-05,
      "loss": 0.1591,
      "step": 85
    },
    {
      "epoch": 0.051165434906196704,
      "grad_norm": 0.15111394226551056,
      "learning_rate": 4.8829724985371564e-05,
      "loss": 0.0657,
      "step": 90
    },
    {
      "epoch": 0.05400795906765207,
      "grad_norm": 0.024609414860606194,
      "learning_rate": 4.8683440608543006e-05,
      "loss": 0.0519,
      "step": 95
    },
    {
      "epoch": 0.05685048322910745,
      "grad_norm": 0.03919416666030884,
      "learning_rate": 4.8537156231714455e-05,
      "loss": 0.1894,
      "step": 100
    },
    {
      "epoch": 0.05969300739056282,
      "grad_norm": 2.8285961151123047,
      "learning_rate": 4.8390871854885897e-05,
      "loss": 0.2762,
      "step": 105
    },
    {
      "epoch": 0.06253553155201819,
      "grad_norm": 0.07196509838104248,
      "learning_rate": 4.8244587478057345e-05,
      "loss": 0.062,
      "step": 110
    },
    {
      "epoch": 0.06537805571347356,
      "grad_norm": 1.5925897359848022,
      "learning_rate": 4.8098303101228794e-05,
      "loss": 0.082,
      "step": 115
    },
    {
      "epoch": 0.06822057987492894,
      "grad_norm": 0.10198891907930374,
      "learning_rate": 4.7952018724400236e-05,
      "loss": 0.0485,
      "step": 120
    },
    {
      "epoch": 0.07106310403638431,
      "grad_norm": 3.075676679611206,
      "learning_rate": 4.780573434757168e-05,
      "loss": 0.2151,
      "step": 125
    },
    {
      "epoch": 0.07390562819783968,
      "grad_norm": 0.11953715980052948,
      "learning_rate": 4.7659449970743126e-05,
      "loss": 0.0702,
      "step": 130
    },
    {
      "epoch": 0.07674815235929505,
      "grad_norm": 1.6674751043319702,
      "learning_rate": 4.7513165593914575e-05,
      "loss": 0.1491,
      "step": 135
    },
    {
      "epoch": 0.07959067652075043,
      "grad_norm": 1.971640944480896,
      "learning_rate": 4.7366881217086017e-05,
      "loss": 0.2448,
      "step": 140
    },
    {
      "epoch": 0.0824332006822058,
      "grad_norm": 0.06290355324745178,
      "learning_rate": 4.7220596840257465e-05,
      "loss": 0.1368,
      "step": 145
    },
    {
      "epoch": 0.08527572484366117,
      "grad_norm": 0.20565848052501678,
      "learning_rate": 4.707431246342891e-05,
      "loss": 0.1675,
      "step": 150
    },
    {
      "epoch": 0.08811824900511654,
      "grad_norm": 0.09019996225833893,
      "learning_rate": 4.692802808660035e-05,
      "loss": 0.0063,
      "step": 155
    },
    {
      "epoch": 0.09096077316657192,
      "grad_norm": 2.2230589389801025,
      "learning_rate": 4.67817437097718e-05,
      "loss": 0.2828,
      "step": 160
    },
    {
      "epoch": 0.0938032973280273,
      "grad_norm": 1.6821582317352295,
      "learning_rate": 4.6635459332943246e-05,
      "loss": 0.1014,
      "step": 165
    },
    {
      "epoch": 0.09664582148948266,
      "grad_norm": 0.15759436786174774,
      "learning_rate": 4.648917495611469e-05,
      "loss": 0.0411,
      "step": 170
    },
    {
      "epoch": 0.09948834565093803,
      "grad_norm": 0.23019346594810486,
      "learning_rate": 4.6342890579286137e-05,
      "loss": 0.1276,
      "step": 175
    },
    {
      "epoch": 0.10233086981239341,
      "grad_norm": 1.6045773029327393,
      "learning_rate": 4.6196606202457585e-05,
      "loss": 0.0962,
      "step": 180
    },
    {
      "epoch": 0.10517339397384878,
      "grad_norm": 0.19999215006828308,
      "learning_rate": 4.605032182562902e-05,
      "loss": 0.0504,
      "step": 185
    },
    {
      "epoch": 0.10801591813530415,
      "grad_norm": 0.35939690470695496,
      "learning_rate": 4.590403744880047e-05,
      "loss": 0.2127,
      "step": 190
    },
    {
      "epoch": 0.11085844229675952,
      "grad_norm": 0.16430753469467163,
      "learning_rate": 4.575775307197192e-05,
      "loss": 0.2095,
      "step": 195
    },
    {
      "epoch": 0.1137009664582149,
      "grad_norm": 1.931788444519043,
      "learning_rate": 4.561146869514336e-05,
      "loss": 0.163,
      "step": 200
    },
    {
      "epoch": 0.11654349061967027,
      "grad_norm": 0.22083987295627594,
      "learning_rate": 4.546518431831481e-05,
      "loss": 0.1369,
      "step": 205
    },
    {
      "epoch": 0.11938601478112564,
      "grad_norm": 1.660453200340271,
      "learning_rate": 4.531889994148626e-05,
      "loss": 0.1441,
      "step": 210
    },
    {
      "epoch": 0.12222853894258101,
      "grad_norm": 2.4351229667663574,
      "learning_rate": 4.517261556465769e-05,
      "loss": 0.2369,
      "step": 215
    },
    {
      "epoch": 0.12507106310403637,
      "grad_norm": 0.21402008831501007,
      "learning_rate": 4.502633118782914e-05,
      "loss": 0.1717,
      "step": 220
    },
    {
      "epoch": 0.12791358726549176,
      "grad_norm": 0.2087978720664978,
      "learning_rate": 4.488004681100059e-05,
      "loss": 0.1424,
      "step": 225
    },
    {
      "epoch": 0.13075611142694712,
      "grad_norm": 1.930741310119629,
      "learning_rate": 4.473376243417203e-05,
      "loss": 0.1322,
      "step": 230
    },
    {
      "epoch": 0.13359863558840251,
      "grad_norm": 0.2442837953567505,
      "learning_rate": 4.458747805734348e-05,
      "loss": 0.1134,
      "step": 235
    },
    {
      "epoch": 0.13644115974985788,
      "grad_norm": 1.787516713142395,
      "learning_rate": 4.444119368051493e-05,
      "loss": 0.2195,
      "step": 240
    },
    {
      "epoch": 0.13928368391131324,
      "grad_norm": 0.15376125276088715,
      "learning_rate": 4.429490930368636e-05,
      "loss": 0.095,
      "step": 245
    },
    {
      "epoch": 0.14212620807276863,
      "grad_norm": 0.1565709114074707,
      "learning_rate": 4.414862492685781e-05,
      "loss": 0.1784,
      "step": 250
    },
    {
      "epoch": 0.144968732234224,
      "grad_norm": 0.1443295031785965,
      "learning_rate": 4.400234055002926e-05,
      "loss": 0.0483,
      "step": 255
    },
    {
      "epoch": 0.14781125639567935,
      "grad_norm": 0.09320499002933502,
      "learning_rate": 4.38560561732007e-05,
      "loss": 0.1943,
      "step": 260
    },
    {
      "epoch": 0.15065378055713474,
      "grad_norm": 0.16126972436904907,
      "learning_rate": 4.370977179637215e-05,
      "loss": 0.1644,
      "step": 265
    },
    {
      "epoch": 0.1534963047185901,
      "grad_norm": 0.16602647304534912,
      "learning_rate": 4.35634874195436e-05,
      "loss": 0.0521,
      "step": 270
    },
    {
      "epoch": 0.1563388288800455,
      "grad_norm": 2.1902759075164795,
      "learning_rate": 4.3417203042715034e-05,
      "loss": 0.2752,
      "step": 275
    },
    {
      "epoch": 0.15918135304150086,
      "grad_norm": 0.15094804763793945,
      "learning_rate": 4.327091866588648e-05,
      "loss": 0.0741,
      "step": 280
    },
    {
      "epoch": 0.16202387720295622,
      "grad_norm": 2.325237989425659,
      "learning_rate": 4.312463428905793e-05,
      "loss": 0.1769,
      "step": 285
    },
    {
      "epoch": 0.1648664013644116,
      "grad_norm": 0.16175667941570282,
      "learning_rate": 4.2978349912229374e-05,
      "loss": 0.0457,
      "step": 290
    },
    {
      "epoch": 0.16770892552586697,
      "grad_norm": 2.431039810180664,
      "learning_rate": 4.283206553540082e-05,
      "loss": 0.1351,
      "step": 295
    },
    {
      "epoch": 0.17055144968732233,
      "grad_norm": 2.1095633506774902,
      "learning_rate": 4.268578115857227e-05,
      "loss": 0.1406,
      "step": 300
    },
    {
      "epoch": 0.17339397384877772,
      "grad_norm": 0.0761277973651886,
      "learning_rate": 4.253949678174371e-05,
      "loss": 0.2647,
      "step": 305
    },
    {
      "epoch": 0.17623649801023308,
      "grad_norm": 1.4015709161758423,
      "learning_rate": 4.2393212404915155e-05,
      "loss": 0.1079,
      "step": 310
    },
    {
      "epoch": 0.17907902217168845,
      "grad_norm": 1.6312459707260132,
      "learning_rate": 4.22469280280866e-05,
      "loss": 0.1751,
      "step": 315
    },
    {
      "epoch": 0.18192154633314384,
      "grad_norm": 0.23413507640361786,
      "learning_rate": 4.2100643651258045e-05,
      "loss": 0.184,
      "step": 320
    },
    {
      "epoch": 0.1847640704945992,
      "grad_norm": 0.3291775584220886,
      "learning_rate": 4.1954359274429494e-05,
      "loss": 0.1636,
      "step": 325
    },
    {
      "epoch": 0.1876065946560546,
      "grad_norm": 0.13518619537353516,
      "learning_rate": 4.180807489760094e-05,
      "loss": 0.0822,
      "step": 330
    },
    {
      "epoch": 0.19044911881750995,
      "grad_norm": 1.6170990467071533,
      "learning_rate": 4.1661790520772384e-05,
      "loss": 0.1638,
      "step": 335
    },
    {
      "epoch": 0.1932916429789653,
      "grad_norm": 0.174725741147995,
      "learning_rate": 4.1515506143943826e-05,
      "loss": 0.1214,
      "step": 340
    },
    {
      "epoch": 0.1961341671404207,
      "grad_norm": 0.12876412272453308,
      "learning_rate": 4.1369221767115275e-05,
      "loss": 0.1725,
      "step": 345
    },
    {
      "epoch": 0.19897669130187606,
      "grad_norm": 1.8666239976882935,
      "learning_rate": 4.122293739028672e-05,
      "loss": 0.0482,
      "step": 350
    },
    {
      "epoch": 0.20181921546333143,
      "grad_norm": 0.09019140899181366,
      "learning_rate": 4.1076653013458165e-05,
      "loss": 0.0005,
      "step": 355
    },
    {
      "epoch": 0.20466173962478681,
      "grad_norm": 0.14314821362495422,
      "learning_rate": 4.0930368636629614e-05,
      "loss": 0.2369,
      "step": 360
    },
    {
      "epoch": 0.20750426378624218,
      "grad_norm": 2.0788211822509766,
      "learning_rate": 4.0784084259801055e-05,
      "loss": 0.0715,
      "step": 365
    },
    {
      "epoch": 0.21034678794769757,
      "grad_norm": 0.05901845544576645,
      "learning_rate": 4.06377998829725e-05,
      "loss": 0.0529,
      "step": 370
    },
    {
      "epoch": 0.21318931210915293,
      "grad_norm": 1.710639476776123,
      "learning_rate": 4.0491515506143946e-05,
      "loss": 0.0817,
      "step": 375
    },
    {
      "epoch": 0.2160318362706083,
      "grad_norm": 0.08127452433109283,
      "learning_rate": 4.0345231129315395e-05,
      "loss": 0.0939,
      "step": 380
    },
    {
      "epoch": 0.21887436043206368,
      "grad_norm": 2.050781726837158,
      "learning_rate": 4.0198946752486836e-05,
      "loss": 0.1778,
      "step": 385
    },
    {
      "epoch": 0.22171688459351904,
      "grad_norm": 1.33448326587677,
      "learning_rate": 4.0052662375658285e-05,
      "loss": 0.1721,
      "step": 390
    },
    {
      "epoch": 0.2245594087549744,
      "grad_norm": 0.2257300317287445,
      "learning_rate": 3.990637799882973e-05,
      "loss": 0.0577,
      "step": 395
    },
    {
      "epoch": 0.2274019329164298,
      "grad_norm": 0.189232736825943,
      "learning_rate": 3.976009362200117e-05,
      "loss": 0.0881,
      "step": 400
    },
    {
      "epoch": 0.23024445707788516,
      "grad_norm": 0.10148894786834717,
      "learning_rate": 3.961380924517262e-05,
      "loss": 0.047,
      "step": 405
    },
    {
      "epoch": 0.23308698123934055,
      "grad_norm": 0.043942175805568695,
      "learning_rate": 3.9467524868344066e-05,
      "loss": 0.1877,
      "step": 410
    },
    {
      "epoch": 0.2359295054007959,
      "grad_norm": 0.12006605416536331,
      "learning_rate": 3.932124049151551e-05,
      "loss": 0.0671,
      "step": 415
    },
    {
      "epoch": 0.23877202956225127,
      "grad_norm": 1.832139253616333,
      "learning_rate": 3.9174956114686956e-05,
      "loss": 0.2206,
      "step": 420
    },
    {
      "epoch": 0.24161455372370666,
      "grad_norm": 0.15572355687618256,
      "learning_rate": 3.90286717378584e-05,
      "loss": 0.123,
      "step": 425
    },
    {
      "epoch": 0.24445707788516202,
      "grad_norm": 1.558526635169983,
      "learning_rate": 3.888238736102984e-05,
      "loss": 0.1022,
      "step": 430
    },
    {
      "epoch": 0.24729960204661738,
      "grad_norm": 1.4557592868804932,
      "learning_rate": 3.873610298420129e-05,
      "loss": 0.1314,
      "step": 435
    },
    {
      "epoch": 0.25014212620807275,
      "grad_norm": 0.3144223093986511,
      "learning_rate": 3.858981860737274e-05,
      "loss": 0.1426,
      "step": 440
    },
    {
      "epoch": 0.25298465036952816,
      "grad_norm": 1.8446664810180664,
      "learning_rate": 3.844353423054418e-05,
      "loss": 0.0993,
      "step": 445
    },
    {
      "epoch": 0.2558271745309835,
      "grad_norm": 1.8790602684020996,
      "learning_rate": 3.829724985371563e-05,
      "loss": 0.119,
      "step": 450
    },
    {
      "epoch": 0.2586696986924389,
      "grad_norm": 0.09653990715742111,
      "learning_rate": 3.815096547688707e-05,
      "loss": 0.1358,
      "step": 455
    },
    {
      "epoch": 0.26151222285389425,
      "grad_norm": 1.8878686428070068,
      "learning_rate": 3.800468110005851e-05,
      "loss": 0.1636,
      "step": 460
    },
    {
      "epoch": 0.2643547470153496,
      "grad_norm": 2.095212697982788,
      "learning_rate": 3.785839672322996e-05,
      "loss": 0.1644,
      "step": 465
    },
    {
      "epoch": 0.26719727117680503,
      "grad_norm": 1.9198836088180542,
      "learning_rate": 3.771211234640141e-05,
      "loss": 0.1311,
      "step": 470
    },
    {
      "epoch": 0.2700397953382604,
      "grad_norm": 0.24323470890522003,
      "learning_rate": 3.756582796957285e-05,
      "loss": 0.166,
      "step": 475
    },
    {
      "epoch": 0.27288231949971575,
      "grad_norm": 1.5504428148269653,
      "learning_rate": 3.74195435927443e-05,
      "loss": 0.0808,
      "step": 480
    },
    {
      "epoch": 0.2757248436611711,
      "grad_norm": 0.2395760416984558,
      "learning_rate": 3.727325921591574e-05,
      "loss": 0.1313,
      "step": 485
    },
    {
      "epoch": 0.2785673678226265,
      "grad_norm": 0.19737499952316284,
      "learning_rate": 3.712697483908719e-05,
      "loss": 0.132,
      "step": 490
    },
    {
      "epoch": 0.28140989198408184,
      "grad_norm": 0.16357018053531647,
      "learning_rate": 3.698069046225863e-05,
      "loss": 0.1125,
      "step": 495
    },
    {
      "epoch": 0.28425241614553726,
      "grad_norm": 1.773012638092041,
      "learning_rate": 3.683440608543008e-05,
      "loss": 0.1354,
      "step": 500
    },
    {
      "epoch": 0.2870949403069926,
      "grad_norm": 1.784952163696289,
      "learning_rate": 3.668812170860152e-05,
      "loss": 0.0782,
      "step": 505
    },
    {
      "epoch": 0.289937464468448,
      "grad_norm": 0.1836065948009491,
      "learning_rate": 3.6541837331772964e-05,
      "loss": 0.1284,
      "step": 510
    },
    {
      "epoch": 0.29277998862990334,
      "grad_norm": 1.6628695726394653,
      "learning_rate": 3.639555295494441e-05,
      "loss": 0.1476,
      "step": 515
    },
    {
      "epoch": 0.2956225127913587,
      "grad_norm": 0.12206494808197021,
      "learning_rate": 3.624926857811586e-05,
      "loss": 0.0015,
      "step": 520
    },
    {
      "epoch": 0.2984650369528141,
      "grad_norm": 1.8316596746444702,
      "learning_rate": 3.61029842012873e-05,
      "loss": 0.2187,
      "step": 525
    },
    {
      "epoch": 0.3013075611142695,
      "grad_norm": 1.7515039443969727,
      "learning_rate": 3.595669982445875e-05,
      "loss": 0.1534,
      "step": 530
    },
    {
      "epoch": 0.30415008527572485,
      "grad_norm": 0.21191559731960297,
      "learning_rate": 3.5810415447630193e-05,
      "loss": 0.073,
      "step": 535
    },
    {
      "epoch": 0.3069926094371802,
      "grad_norm": 1.3193000555038452,
      "learning_rate": 3.5664131070801635e-05,
      "loss": 0.0701,
      "step": 540
    },
    {
      "epoch": 0.30983513359863557,
      "grad_norm": 0.1917245239019394,
      "learning_rate": 3.5517846693973084e-05,
      "loss": 0.2147,
      "step": 545
    },
    {
      "epoch": 0.312677657760091,
      "grad_norm": 0.2324153631925583,
      "learning_rate": 3.537156231714453e-05,
      "loss": 0.0588,
      "step": 550
    },
    {
      "epoch": 0.31552018192154635,
      "grad_norm": 1.7659883499145508,
      "learning_rate": 3.5225277940315974e-05,
      "loss": 0.2381,
      "step": 555
    },
    {
      "epoch": 0.3183627060830017,
      "grad_norm": 1.3599814176559448,
      "learning_rate": 3.507899356348742e-05,
      "loss": 0.0758,
      "step": 560
    },
    {
      "epoch": 0.3212052302444571,
      "grad_norm": 1.325061559677124,
      "learning_rate": 3.493270918665887e-05,
      "loss": 0.0849,
      "step": 565
    },
    {
      "epoch": 0.32404775440591244,
      "grad_norm": 1.4536062479019165,
      "learning_rate": 3.478642480983031e-05,
      "loss": 0.1473,
      "step": 570
    },
    {
      "epoch": 0.3268902785673678,
      "grad_norm": 0.14239443838596344,
      "learning_rate": 3.4640140433001755e-05,
      "loss": 0.0772,
      "step": 575
    },
    {
      "epoch": 0.3297328027288232,
      "grad_norm": 1.6305129528045654,
      "learning_rate": 3.4493856056173204e-05,
      "loss": 0.0991,
      "step": 580
    },
    {
      "epoch": 0.3325753268902786,
      "grad_norm": 0.09939828515052795,
      "learning_rate": 3.4347571679344646e-05,
      "loss": 0.0938,
      "step": 585
    },
    {
      "epoch": 0.33541785105173394,
      "grad_norm": 1.1829723119735718,
      "learning_rate": 3.4201287302516094e-05,
      "loss": 0.1378,
      "step": 590
    },
    {
      "epoch": 0.3382603752131893,
      "grad_norm": 0.18450860679149628,
      "learning_rate": 3.405500292568754e-05,
      "loss": 0.148,
      "step": 595
    },
    {
      "epoch": 0.34110289937464466,
      "grad_norm": 0.15487073361873627,
      "learning_rate": 3.390871854885898e-05,
      "loss": 0.0453,
      "step": 600
    },
    {
      "epoch": 0.3439454235361001,
      "grad_norm": 0.0965612456202507,
      "learning_rate": 3.376243417203043e-05,
      "loss": 0.0017,
      "step": 605
    },
    {
      "epoch": 0.34678794769755544,
      "grad_norm": 0.04968610405921936,
      "learning_rate": 3.3616149795201875e-05,
      "loss": 0.0006,
      "step": 610
    },
    {
      "epoch": 0.3496304718590108,
      "grad_norm": 2.107041835784912,
      "learning_rate": 3.346986541837332e-05,
      "loss": 0.1561,
      "step": 615
    },
    {
      "epoch": 0.35247299602046617,
      "grad_norm": 1.38384211063385,
      "learning_rate": 3.3323581041544766e-05,
      "loss": 0.0682,
      "step": 620
    },
    {
      "epoch": 0.35531552018192153,
      "grad_norm": 1.9877893924713135,
      "learning_rate": 3.3177296664716214e-05,
      "loss": 0.1688,
      "step": 625
    },
    {
      "epoch": 0.3581580443433769,
      "grad_norm": 0.12734360992908478,
      "learning_rate": 3.303101228788765e-05,
      "loss": 0.0662,
      "step": 630
    },
    {
      "epoch": 0.3610005685048323,
      "grad_norm": 1.4488683938980103,
      "learning_rate": 3.28847279110591e-05,
      "loss": 0.0556,
      "step": 635
    },
    {
      "epoch": 0.36384309266628767,
      "grad_norm": 1.362375020980835,
      "learning_rate": 3.273844353423055e-05,
      "loss": 0.1184,
      "step": 640
    },
    {
      "epoch": 0.36668561682774303,
      "grad_norm": 1.876738429069519,
      "learning_rate": 3.259215915740199e-05,
      "loss": 0.1778,
      "step": 645
    },
    {
      "epoch": 0.3695281409891984,
      "grad_norm": 1.3558659553527832,
      "learning_rate": 3.244587478057344e-05,
      "loss": 0.1746,
      "step": 650
    },
    {
      "epoch": 0.37237066515065376,
      "grad_norm": 1.596092939376831,
      "learning_rate": 3.2299590403744886e-05,
      "loss": 0.0502,
      "step": 655
    },
    {
      "epoch": 0.3752131893121092,
      "grad_norm": 0.23431465029716492,
      "learning_rate": 3.215330602691633e-05,
      "loss": 0.1353,
      "step": 660
    },
    {
      "epoch": 0.37805571347356454,
      "grad_norm": 1.5897096395492554,
      "learning_rate": 3.200702165008777e-05,
      "loss": 0.1548,
      "step": 665
    },
    {
      "epoch": 0.3808982376350199,
      "grad_norm": 0.09536058455705643,
      "learning_rate": 3.186073727325922e-05,
      "loss": 0.001,
      "step": 670
    },
    {
      "epoch": 0.38374076179647526,
      "grad_norm": 1.535465955734253,
      "learning_rate": 3.171445289643066e-05,
      "loss": 0.1733,
      "step": 675
    },
    {
      "epoch": 0.3865832859579306,
      "grad_norm": 1.4677964448928833,
      "learning_rate": 3.156816851960211e-05,
      "loss": 0.1741,
      "step": 680
    },
    {
      "epoch": 0.38942581011938604,
      "grad_norm": 1.521043062210083,
      "learning_rate": 3.142188414277356e-05,
      "loss": 0.0589,
      "step": 685
    },
    {
      "epoch": 0.3922683342808414,
      "grad_norm": 1.3771463632583618,
      "learning_rate": 3.1275599765945e-05,
      "loss": 0.1932,
      "step": 690
    },
    {
      "epoch": 0.39511085844229676,
      "grad_norm": 1.5466289520263672,
      "learning_rate": 3.112931538911644e-05,
      "loss": 0.0989,
      "step": 695
    },
    {
      "epoch": 0.3979533826037521,
      "grad_norm": 1.7979850769042969,
      "learning_rate": 3.098303101228789e-05,
      "loss": 0.2225,
      "step": 700
    },
    {
      "epoch": 0.4007959067652075,
      "grad_norm": 1.6976836919784546,
      "learning_rate": 3.083674663545934e-05,
      "loss": 0.2121,
      "step": 705
    },
    {
      "epoch": 0.40363843092666285,
      "grad_norm": 0.22697891294956207,
      "learning_rate": 3.069046225863078e-05,
      "loss": 0.0015,
      "step": 710
    },
    {
      "epoch": 0.40648095508811827,
      "grad_norm": 0.17785480618476868,
      "learning_rate": 3.054417788180223e-05,
      "loss": 0.1423,
      "step": 715
    },
    {
      "epoch": 0.40932347924957363,
      "grad_norm": 0.12194827198982239,
      "learning_rate": 3.0397893504973667e-05,
      "loss": 0.0019,
      "step": 720
    },
    {
      "epoch": 0.412166003411029,
      "grad_norm": 1.558099627494812,
      "learning_rate": 3.0251609128145116e-05,
      "loss": 0.1618,
      "step": 725
    },
    {
      "epoch": 0.41500852757248435,
      "grad_norm": 0.06333030015230179,
      "learning_rate": 3.010532475131656e-05,
      "loss": 0.1526,
      "step": 730
    },
    {
      "epoch": 0.4178510517339397,
      "grad_norm": 1.259743332862854,
      "learning_rate": 2.9959040374488006e-05,
      "loss": 0.0674,
      "step": 735
    },
    {
      "epoch": 0.42069357589539513,
      "grad_norm": 0.10184434801340103,
      "learning_rate": 2.981275599765945e-05,
      "loss": 0.1118,
      "step": 740
    },
    {
      "epoch": 0.4235361000568505,
      "grad_norm": 0.11716022342443466,
      "learning_rate": 2.96664716208309e-05,
      "loss": 0.0397,
      "step": 745
    },
    {
      "epoch": 0.42637862421830586,
      "grad_norm": 1.3130766153335571,
      "learning_rate": 2.952018724400234e-05,
      "loss": 0.2346,
      "step": 750
    },
    {
      "epoch": 0.4292211483797612,
      "grad_norm": 1.2444971799850464,
      "learning_rate": 2.9373902867173787e-05,
      "loss": 0.1607,
      "step": 755
    },
    {
      "epoch": 0.4320636725412166,
      "grad_norm": 1.1753953695297241,
      "learning_rate": 2.9227618490345232e-05,
      "loss": 0.1773,
      "step": 760
    },
    {
      "epoch": 0.434906196702672,
      "grad_norm": 0.2862546145915985,
      "learning_rate": 2.9081334113516678e-05,
      "loss": 0.1218,
      "step": 765
    },
    {
      "epoch": 0.43774872086412736,
      "grad_norm": 0.21493516862392426,
      "learning_rate": 2.8935049736688126e-05,
      "loss": 0.0372,
      "step": 770
    },
    {
      "epoch": 0.4405912450255827,
      "grad_norm": 1.3439801931381226,
      "learning_rate": 2.878876535985957e-05,
      "loss": 0.1233,
      "step": 775
    },
    {
      "epoch": 0.4434337691870381,
      "grad_norm": 0.1611817330121994,
      "learning_rate": 2.864248098303101e-05,
      "loss": 0.0429,
      "step": 780
    },
    {
      "epoch": 0.44627629334849345,
      "grad_norm": 0.14310480654239655,
      "learning_rate": 2.849619660620246e-05,
      "loss": 0.1538,
      "step": 785
    },
    {
      "epoch": 0.4491188175099488,
      "grad_norm": 0.11697021871805191,
      "learning_rate": 2.8349912229373904e-05,
      "loss": 0.0354,
      "step": 790
    },
    {
      "epoch": 0.4519613416714042,
      "grad_norm": 0.1086202934384346,
      "learning_rate": 2.820362785254535e-05,
      "loss": 0.0787,
      "step": 795
    },
    {
      "epoch": 0.4548038658328596,
      "grad_norm": 0.10844743251800537,
      "learning_rate": 2.8057343475716798e-05,
      "loss": 0.2078,
      "step": 800
    },
    {
      "epoch": 0.45764638999431495,
      "grad_norm": 0.0868498906493187,
      "learning_rate": 2.7911059098888243e-05,
      "loss": 0.0632,
      "step": 805
    },
    {
      "epoch": 0.4604889141557703,
      "grad_norm": 1.2648630142211914,
      "learning_rate": 2.7764774722059685e-05,
      "loss": 0.1247,
      "step": 810
    },
    {
      "epoch": 0.4633314383172257,
      "grad_norm": 0.10551881790161133,
      "learning_rate": 2.761849034523113e-05,
      "loss": 0.0015,
      "step": 815
    },
    {
      "epoch": 0.4661739624786811,
      "grad_norm": 1.422275424003601,
      "learning_rate": 2.7472205968402575e-05,
      "loss": 0.2072,
      "step": 820
    },
    {
      "epoch": 0.46901648664013645,
      "grad_norm": 0.12558378279209137,
      "learning_rate": 2.732592159157402e-05,
      "loss": 0.0823,
      "step": 825
    },
    {
      "epoch": 0.4718590108015918,
      "grad_norm": 1.189011573791504,
      "learning_rate": 2.717963721474547e-05,
      "loss": 0.1424,
      "step": 830
    },
    {
      "epoch": 0.4747015349630472,
      "grad_norm": 1.653570532798767,
      "learning_rate": 2.7033352837916914e-05,
      "loss": 0.0842,
      "step": 835
    },
    {
      "epoch": 0.47754405912450254,
      "grad_norm": 1.302156686782837,
      "learning_rate": 2.6887068461088356e-05,
      "loss": 0.2272,
      "step": 840
    },
    {
      "epoch": 0.48038658328595796,
      "grad_norm": 0.12049692124128342,
      "learning_rate": 2.67407840842598e-05,
      "loss": 0.0699,
      "step": 845
    },
    {
      "epoch": 0.4832291074474133,
      "grad_norm": 0.1401359736919403,
      "learning_rate": 2.6594499707431246e-05,
      "loss": 0.0455,
      "step": 850
    },
    {
      "epoch": 0.4860716316088687,
      "grad_norm": 0.0557662695646286,
      "learning_rate": 2.6448215330602695e-05,
      "loss": 0.084,
      "step": 855
    },
    {
      "epoch": 0.48891415577032404,
      "grad_norm": 1.1964068412780762,
      "learning_rate": 2.630193095377414e-05,
      "loss": 0.1811,
      "step": 860
    },
    {
      "epoch": 0.4917566799317794,
      "grad_norm": 1.5056596994400024,
      "learning_rate": 2.6155646576945586e-05,
      "loss": 0.1421,
      "step": 865
    },
    {
      "epoch": 0.49459920409323477,
      "grad_norm": 0.16575054824352264,
      "learning_rate": 2.6009362200117027e-05,
      "loss": 0.1301,
      "step": 870
    },
    {
      "epoch": 0.4974417282546902,
      "grad_norm": 0.1603369265794754,
      "learning_rate": 2.5863077823288473e-05,
      "loss": 0.1486,
      "step": 875
    },
    {
      "epoch": 0.5002842524161455,
      "grad_norm": 1.1864571571350098,
      "learning_rate": 2.5716793446459918e-05,
      "loss": 0.136,
      "step": 880
    },
    {
      "epoch": 0.503126776577601,
      "grad_norm": 0.1855243295431137,
      "learning_rate": 2.5570509069631366e-05,
      "loss": 0.0014,
      "step": 885
    },
    {
      "epoch": 0.5059693007390563,
      "grad_norm": 0.16469617187976837,
      "learning_rate": 2.5424224692802812e-05,
      "loss": 0.1251,
      "step": 890
    },
    {
      "epoch": 0.5088118249005117,
      "grad_norm": 2.029005527496338,
      "learning_rate": 2.5277940315974257e-05,
      "loss": 0.2075,
      "step": 895
    },
    {
      "epoch": 0.511654349061967,
      "grad_norm": 0.09692191332578659,
      "learning_rate": 2.51316559391457e-05,
      "loss": 0.0389,
      "step": 900
    },
    {
      "epoch": 0.5144968732234224,
      "grad_norm": 0.06189345568418503,
      "learning_rate": 2.4985371562317144e-05,
      "loss": 0.0007,
      "step": 905
    },
    {
      "epoch": 0.5173393973848778,
      "grad_norm": 1.8368940353393555,
      "learning_rate": 2.483908718548859e-05,
      "loss": 0.097,
      "step": 910
    },
    {
      "epoch": 0.5201819215463331,
      "grad_norm": 1.145869255065918,
      "learning_rate": 2.4692802808660038e-05,
      "loss": 0.1236,
      "step": 915
    },
    {
      "epoch": 0.5230244457077885,
      "grad_norm": 1.2097340822219849,
      "learning_rate": 2.454651843183148e-05,
      "loss": 0.0935,
      "step": 920
    },
    {
      "epoch": 0.5258669698692439,
      "grad_norm": 0.126224085688591,
      "learning_rate": 2.440023405500293e-05,
      "loss": 0.1013,
      "step": 925
    },
    {
      "epoch": 0.5287094940306992,
      "grad_norm": 1.227308750152588,
      "learning_rate": 2.4253949678174374e-05,
      "loss": 0.1586,
      "step": 930
    },
    {
      "epoch": 0.5315520181921546,
      "grad_norm": 0.15345759689807892,
      "learning_rate": 2.4107665301345815e-05,
      "loss": 0.0583,
      "step": 935
    },
    {
      "epoch": 0.5343945423536101,
      "grad_norm": 1.15410315990448,
      "learning_rate": 2.3961380924517264e-05,
      "loss": 0.1433,
      "step": 940
    },
    {
      "epoch": 0.5372370665150654,
      "grad_norm": 0.16439305245876312,
      "learning_rate": 2.381509654768871e-05,
      "loss": 0.0968,
      "step": 945
    },
    {
      "epoch": 0.5400795906765208,
      "grad_norm": 1.4106476306915283,
      "learning_rate": 2.366881217086015e-05,
      "loss": 0.1317,
      "step": 950
    },
    {
      "epoch": 0.5429221148379761,
      "grad_norm": 1.8161157369613647,
      "learning_rate": 2.35225277940316e-05,
      "loss": 0.0901,
      "step": 955
    },
    {
      "epoch": 0.5457646389994315,
      "grad_norm": 1.5092625617980957,
      "learning_rate": 2.3376243417203045e-05,
      "loss": 0.2432,
      "step": 960
    },
    {
      "epoch": 0.5486071631608869,
      "grad_norm": 0.16191978752613068,
      "learning_rate": 2.3229959040374487e-05,
      "loss": 0.0308,
      "step": 965
    },
    {
      "epoch": 0.5514496873223422,
      "grad_norm": 0.23443132638931274,
      "learning_rate": 2.3083674663545935e-05,
      "loss": 0.1428,
      "step": 970
    },
    {
      "epoch": 0.5542922114837976,
      "grad_norm": 1.3521573543548584,
      "learning_rate": 2.293739028671738e-05,
      "loss": 0.084,
      "step": 975
    },
    {
      "epoch": 0.557134735645253,
      "grad_norm": 1.7479745149612427,
      "learning_rate": 2.2791105909888823e-05,
      "loss": 0.2233,
      "step": 980
    },
    {
      "epoch": 0.5599772598067083,
      "grad_norm": 0.14418691396713257,
      "learning_rate": 2.264482153306027e-05,
      "loss": 0.0758,
      "step": 985
    },
    {
      "epoch": 0.5628197839681637,
      "grad_norm": 0.1554994285106659,
      "learning_rate": 2.2498537156231716e-05,
      "loss": 0.0397,
      "step": 990
    },
    {
      "epoch": 0.5656623081296192,
      "grad_norm": 0.0899471789598465,
      "learning_rate": 2.235225277940316e-05,
      "loss": 0.0688,
      "step": 995
    },
    {
      "epoch": 0.5685048322910745,
      "grad_norm": 0.06529412418603897,
      "learning_rate": 2.2205968402574607e-05,
      "loss": 0.0013,
      "step": 1000
    },
    {
      "epoch": 0.5713473564525299,
      "grad_norm": 1.457767128944397,
      "learning_rate": 2.2059684025746052e-05,
      "loss": 0.0424,
      "step": 1005
    },
    {
      "epoch": 0.5741898806139852,
      "grad_norm": 0.058906104415655136,
      "learning_rate": 2.1913399648917497e-05,
      "loss": 0.1493,
      "step": 1010
    },
    {
      "epoch": 0.5770324047754406,
      "grad_norm": 0.05790451914072037,
      "learning_rate": 2.1767115272088943e-05,
      "loss": 0.0592,
      "step": 1015
    },
    {
      "epoch": 0.579874928936896,
      "grad_norm": 0.07518339157104492,
      "learning_rate": 2.1620830895260388e-05,
      "loss": 0.1772,
      "step": 1020
    },
    {
      "epoch": 0.5827174530983513,
      "grad_norm": 1.4319614171981812,
      "learning_rate": 2.1474546518431833e-05,
      "loss": 0.1031,
      "step": 1025
    },
    {
      "epoch": 0.5855599772598067,
      "grad_norm": 0.14348240196704865,
      "learning_rate": 2.1328262141603278e-05,
      "loss": 0.1599,
      "step": 1030
    },
    {
      "epoch": 0.588402501421262,
      "grad_norm": 0.16450583934783936,
      "learning_rate": 2.1181977764774723e-05,
      "loss": 0.1391,
      "step": 1035
    },
    {
      "epoch": 0.5912450255827174,
      "grad_norm": 0.17807874083518982,
      "learning_rate": 2.103569338794617e-05,
      "loss": 0.0759,
      "step": 1040
    },
    {
      "epoch": 0.5940875497441728,
      "grad_norm": 0.19729946553707123,
      "learning_rate": 2.0889409011117614e-05,
      "loss": 0.0938,
      "step": 1045
    },
    {
      "epoch": 0.5969300739056282,
      "grad_norm": 0.158675879240036,
      "learning_rate": 2.074312463428906e-05,
      "loss": 0.0697,
      "step": 1050
    },
    {
      "epoch": 0.5997725980670836,
      "grad_norm": 1.3429065942764282,
      "learning_rate": 2.0596840257460504e-05,
      "loss": 0.1833,
      "step": 1055
    },
    {
      "epoch": 0.602615122228539,
      "grad_norm": 0.15974585711956024,
      "learning_rate": 2.045055588063195e-05,
      "loss": 0.1055,
      "step": 1060
    },
    {
      "epoch": 0.6054576463899943,
      "grad_norm": 0.14434543251991272,
      "learning_rate": 2.0304271503803395e-05,
      "loss": 0.0803,
      "step": 1065
    },
    {
      "epoch": 0.6083001705514497,
      "grad_norm": 1.491305947303772,
      "learning_rate": 2.015798712697484e-05,
      "loss": 0.225,
      "step": 1070
    },
    {
      "epoch": 0.611142694712905,
      "grad_norm": 1.3317241668701172,
      "learning_rate": 2.0011702750146285e-05,
      "loss": 0.183,
      "step": 1075
    },
    {
      "epoch": 0.6139852188743604,
      "grad_norm": 0.2112235724925995,
      "learning_rate": 1.986541837331773e-05,
      "loss": 0.232,
      "step": 1080
    },
    {
      "epoch": 0.6168277430358158,
      "grad_norm": 0.25790396332740784,
      "learning_rate": 1.9719133996489176e-05,
      "loss": 0.0642,
      "step": 1085
    },
    {
      "epoch": 0.6196702671972711,
      "grad_norm": 0.9953043460845947,
      "learning_rate": 1.957284961966062e-05,
      "loss": 0.0969,
      "step": 1090
    },
    {
      "epoch": 0.6225127913587265,
      "grad_norm": 0.21166706085205078,
      "learning_rate": 1.9426565242832066e-05,
      "loss": 0.1678,
      "step": 1095
    },
    {
      "epoch": 0.625355315520182,
      "grad_norm": 0.151882603764534,
      "learning_rate": 1.928028086600351e-05,
      "loss": 0.088,
      "step": 1100
    },
    {
      "epoch": 0.6281978396816373,
      "grad_norm": 1.0059195756912231,
      "learning_rate": 1.9133996489174957e-05,
      "loss": 0.1755,
      "step": 1105
    },
    {
      "epoch": 0.6310403638430927,
      "grad_norm": 0.1984349489212036,
      "learning_rate": 1.8987712112346402e-05,
      "loss": 0.1097,
      "step": 1110
    },
    {
      "epoch": 0.6338828880045481,
      "grad_norm": 1.3267991542816162,
      "learning_rate": 1.8841427735517847e-05,
      "loss": 0.1855,
      "step": 1115
    },
    {
      "epoch": 0.6367254121660034,
      "grad_norm": 0.18024934828281403,
      "learning_rate": 1.8695143358689292e-05,
      "loss": 0.0514,
      "step": 1120
    },
    {
      "epoch": 0.6395679363274588,
      "grad_norm": 0.16895420849323273,
      "learning_rate": 1.854885898186074e-05,
      "loss": 0.0875,
      "step": 1125
    },
    {
      "epoch": 0.6424104604889141,
      "grad_norm": 0.15858447551727295,
      "learning_rate": 1.8402574605032183e-05,
      "loss": 0.1201,
      "step": 1130
    },
    {
      "epoch": 0.6452529846503695,
      "grad_norm": 0.07128485292196274,
      "learning_rate": 1.8256290228203628e-05,
      "loss": 0.0713,
      "step": 1135
    },
    {
      "epoch": 0.6480955088118249,
      "grad_norm": 1.0293654203414917,
      "learning_rate": 1.8110005851375077e-05,
      "loss": 0.0703,
      "step": 1140
    },
    {
      "epoch": 0.6509380329732802,
      "grad_norm": 0.11217452585697174,
      "learning_rate": 1.796372147454652e-05,
      "loss": 0.0678,
      "step": 1145
    },
    {
      "epoch": 0.6537805571347356,
      "grad_norm": 0.1317310929298401,
      "learning_rate": 1.7817437097717964e-05,
      "loss": 0.0623,
      "step": 1150
    },
    {
      "epoch": 0.6566230812961911,
      "grad_norm": 1.3149018287658691,
      "learning_rate": 1.7671152720889412e-05,
      "loss": 0.0731,
      "step": 1155
    },
    {
      "epoch": 0.6594656054576464,
      "grad_norm": 1.3032907247543335,
      "learning_rate": 1.7524868344060854e-05,
      "loss": 0.0968,
      "step": 1160
    },
    {
      "epoch": 0.6623081296191018,
      "grad_norm": 1.165231466293335,
      "learning_rate": 1.73785839672323e-05,
      "loss": 0.0742,
      "step": 1165
    },
    {
      "epoch": 0.6651506537805572,
      "grad_norm": 0.14413344860076904,
      "learning_rate": 1.7232299590403748e-05,
      "loss": 0.0573,
      "step": 1170
    },
    {
      "epoch": 0.6679931779420125,
      "grad_norm": 1.3359163999557495,
      "learning_rate": 1.708601521357519e-05,
      "loss": 0.1151,
      "step": 1175
    },
    {
      "epoch": 0.6708357021034679,
      "grad_norm": 0.11284487694501877,
      "learning_rate": 1.6939730836746635e-05,
      "loss": 0.1091,
      "step": 1180
    },
    {
      "epoch": 0.6736782262649232,
      "grad_norm": 0.14501787722110748,
      "learning_rate": 1.679344645991808e-05,
      "loss": 0.0857,
      "step": 1185
    },
    {
      "epoch": 0.6765207504263786,
      "grad_norm": 0.1540381908416748,
      "learning_rate": 1.6647162083089526e-05,
      "loss": 0.1319,
      "step": 1190
    },
    {
      "epoch": 0.679363274587834,
      "grad_norm": 0.2100781947374344,
      "learning_rate": 1.650087770626097e-05,
      "loss": 0.1518,
      "step": 1195
    },
    {
      "epoch": 0.6822057987492893,
      "grad_norm": 1.2836370468139648,
      "learning_rate": 1.6354593329432416e-05,
      "loss": 0.1576,
      "step": 1200
    },
    {
      "epoch": 0.6850483229107447,
      "grad_norm": 0.2588009536266327,
      "learning_rate": 1.620830895260386e-05,
      "loss": 0.1024,
      "step": 1205
    },
    {
      "epoch": 0.6878908470722002,
      "grad_norm": 0.16499194502830505,
      "learning_rate": 1.606202457577531e-05,
      "loss": 0.0846,
      "step": 1210
    },
    {
      "epoch": 0.6907333712336555,
      "grad_norm": 0.17758817970752716,
      "learning_rate": 1.5915740198946752e-05,
      "loss": 0.1109,
      "step": 1215
    },
    {
      "epoch": 0.6935758953951109,
      "grad_norm": 0.12847325205802917,
      "learning_rate": 1.5769455822118197e-05,
      "loss": 0.0968,
      "step": 1220
    },
    {
      "epoch": 0.6964184195565662,
      "grad_norm": 0.9896711111068726,
      "learning_rate": 1.5623171445289646e-05,
      "loss": 0.1499,
      "step": 1225
    },
    {
      "epoch": 0.6992609437180216,
      "grad_norm": 0.1587999165058136,
      "learning_rate": 1.5476887068461088e-05,
      "loss": 0.1048,
      "step": 1230
    },
    {
      "epoch": 0.702103467879477,
      "grad_norm": 1.4419077634811401,
      "learning_rate": 1.5330602691632533e-05,
      "loss": 0.205,
      "step": 1235
    },
    {
      "epoch": 0.7049459920409323,
      "grad_norm": 1.5955982208251953,
      "learning_rate": 1.518431831480398e-05,
      "loss": 0.1674,
      "step": 1240
    },
    {
      "epoch": 0.7077885162023877,
      "grad_norm": 0.22574816644191742,
      "learning_rate": 1.5038033937975423e-05,
      "loss": 0.1904,
      "step": 1245
    },
    {
      "epoch": 0.7106310403638431,
      "grad_norm": 0.19012802839279175,
      "learning_rate": 1.489174956114687e-05,
      "loss": 0.1063,
      "step": 1250
    },
    {
      "epoch": 0.7134735645252984,
      "grad_norm": 1.6182291507720947,
      "learning_rate": 1.4745465184318315e-05,
      "loss": 0.2415,
      "step": 1255
    },
    {
      "epoch": 0.7163160886867538,
      "grad_norm": 1.2998493909835815,
      "learning_rate": 1.4599180807489759e-05,
      "loss": 0.1731,
      "step": 1260
    },
    {
      "epoch": 0.7191586128482093,
      "grad_norm": 1.2902158498764038,
      "learning_rate": 1.4452896430661206e-05,
      "loss": 0.1913,
      "step": 1265
    },
    {
      "epoch": 0.7220011370096646,
      "grad_norm": 0.24632297456264496,
      "learning_rate": 1.4306612053832653e-05,
      "loss": 0.1434,
      "step": 1270
    },
    {
      "epoch": 0.72484366117112,
      "grad_norm": 1.241524338722229,
      "learning_rate": 1.4160327677004095e-05,
      "loss": 0.1641,
      "step": 1275
    },
    {
      "epoch": 0.7276861853325753,
      "grad_norm": 1.1702100038528442,
      "learning_rate": 1.4014043300175542e-05,
      "loss": 0.062,
      "step": 1280
    },
    {
      "epoch": 0.7305287094940307,
      "grad_norm": 0.21103043854236603,
      "learning_rate": 1.3867758923346989e-05,
      "loss": 0.0683,
      "step": 1285
    },
    {
      "epoch": 0.7333712336554861,
      "grad_norm": 1.336372971534729,
      "learning_rate": 1.3721474546518432e-05,
      "loss": 0.1282,
      "step": 1290
    },
    {
      "epoch": 0.7362137578169414,
      "grad_norm": 1.145464301109314,
      "learning_rate": 1.3575190169689877e-05,
      "loss": 0.0757,
      "step": 1295
    },
    {
      "epoch": 0.7390562819783968,
      "grad_norm": 0.11250486224889755,
      "learning_rate": 1.3428905792861324e-05,
      "loss": 0.1222,
      "step": 1300
    },
    {
      "epoch": 0.7418988061398522,
      "grad_norm": 0.18754585087299347,
      "learning_rate": 1.3282621416032768e-05,
      "loss": 0.0534,
      "step": 1305
    },
    {
      "epoch": 0.7447413303013075,
      "grad_norm": 1.264681100845337,
      "learning_rate": 1.3136337039204213e-05,
      "loss": 0.0682,
      "step": 1310
    },
    {
      "epoch": 0.747583854462763,
      "grad_norm": 0.33874601125717163,
      "learning_rate": 1.299005266237566e-05,
      "loss": 0.0621,
      "step": 1315
    },
    {
      "epoch": 0.7504263786242183,
      "grad_norm": 0.16103015840053558,
      "learning_rate": 1.2843768285547103e-05,
      "loss": 0.0803,
      "step": 1320
    },
    {
      "epoch": 0.7532689027856737,
      "grad_norm": 1.0759271383285522,
      "learning_rate": 1.2697483908718549e-05,
      "loss": 0.1226,
      "step": 1325
    },
    {
      "epoch": 0.7561114269471291,
      "grad_norm": 1.347658395767212,
      "learning_rate": 1.2551199531889996e-05,
      "loss": 0.1833,
      "step": 1330
    },
    {
      "epoch": 0.7589539511085844,
      "grad_norm": 1.3243904113769531,
      "learning_rate": 1.2404915155061441e-05,
      "loss": 0.1834,
      "step": 1335
    },
    {
      "epoch": 0.7617964752700398,
      "grad_norm": 0.15370145440101624,
      "learning_rate": 1.2258630778232884e-05,
      "loss": 0.0396,
      "step": 1340
    },
    {
      "epoch": 0.7646389994314952,
      "grad_norm": 1.295573115348816,
      "learning_rate": 1.211234640140433e-05,
      "loss": 0.1401,
      "step": 1345
    },
    {
      "epoch": 0.7674815235929505,
      "grad_norm": 0.14675648510456085,
      "learning_rate": 1.1966062024575777e-05,
      "loss": 0.2005,
      "step": 1350
    },
    {
      "epoch": 0.7703240477544059,
      "grad_norm": 0.11919281631708145,
      "learning_rate": 1.1819777647747222e-05,
      "loss": 0.0948,
      "step": 1355
    },
    {
      "epoch": 0.7731665719158612,
      "grad_norm": 1.2846789360046387,
      "learning_rate": 1.1673493270918665e-05,
      "loss": 0.0694,
      "step": 1360
    },
    {
      "epoch": 0.7760090960773166,
      "grad_norm": 0.2484155148267746,
      "learning_rate": 1.1527208894090112e-05,
      "loss": 0.1144,
      "step": 1365
    },
    {
      "epoch": 0.7788516202387721,
      "grad_norm": 1.101981282234192,
      "learning_rate": 1.1380924517261557e-05,
      "loss": 0.0883,
      "step": 1370
    },
    {
      "epoch": 0.7816941444002274,
      "grad_norm": 0.10744019597768784,
      "learning_rate": 1.1234640140433001e-05,
      "loss": 0.0014,
      "step": 1375
    },
    {
      "epoch": 0.7845366685616828,
      "grad_norm": 1.0496195554733276,
      "learning_rate": 1.1088355763604448e-05,
      "loss": 0.1295,
      "step": 1380
    },
    {
      "epoch": 0.7873791927231382,
      "grad_norm": 0.12100997567176819,
      "learning_rate": 1.0942071386775893e-05,
      "loss": 0.0732,
      "step": 1385
    },
    {
      "epoch": 0.7902217168845935,
      "grad_norm": 1.3386614322662354,
      "learning_rate": 1.0795787009947338e-05,
      "loss": 0.0954,
      "step": 1390
    },
    {
      "epoch": 0.7930642410460489,
      "grad_norm": 0.11788546293973923,
      "learning_rate": 1.0649502633118784e-05,
      "loss": 0.0884,
      "step": 1395
    },
    {
      "epoch": 0.7959067652075043,
      "grad_norm": 0.08200180530548096,
      "learning_rate": 1.0503218256290229e-05,
      "loss": 0.0008,
      "step": 1400
    },
    {
      "epoch": 0.7987492893689596,
      "grad_norm": 0.09940711408853531,
      "learning_rate": 1.0356933879461674e-05,
      "loss": 0.1207,
      "step": 1405
    },
    {
      "epoch": 0.801591813530415,
      "grad_norm": 0.07067760080099106,
      "learning_rate": 1.021064950263312e-05,
      "loss": 0.1955,
      "step": 1410
    },
    {
      "epoch": 0.8044343376918703,
      "grad_norm": 1.1878681182861328,
      "learning_rate": 1.0064365125804565e-05,
      "loss": 0.0821,
      "step": 1415
    },
    {
      "epoch": 0.8072768618533257,
      "grad_norm": 1.411881685256958,
      "learning_rate": 9.91808074897601e-06,
      "loss": 0.1267,
      "step": 1420
    },
    {
      "epoch": 0.8101193860147812,
      "grad_norm": 1.2395485639572144,
      "learning_rate": 9.771796372147455e-06,
      "loss": 0.219,
      "step": 1425
    },
    {
      "epoch": 0.8129619101762365,
      "grad_norm": 1.0023967027664185,
      "learning_rate": 9.6255119953189e-06,
      "loss": 0.0714,
      "step": 1430
    },
    {
      "epoch": 0.8158044343376919,
      "grad_norm": 1.5324089527130127,
      "learning_rate": 9.479227618490346e-06,
      "loss": 0.1976,
      "step": 1435
    },
    {
      "epoch": 0.8186469584991473,
      "grad_norm": 0.15605109930038452,
      "learning_rate": 9.33294324166179e-06,
      "loss": 0.0938,
      "step": 1440
    },
    {
      "epoch": 0.8214894826606026,
      "grad_norm": 0.13034388422966003,
      "learning_rate": 9.186658864833236e-06,
      "loss": 0.0433,
      "step": 1445
    },
    {
      "epoch": 0.824332006822058,
      "grad_norm": 0.1785314679145813,
      "learning_rate": 9.040374488004681e-06,
      "loss": 0.0533,
      "step": 1450
    },
    {
      "epoch": 0.8271745309835133,
      "grad_norm": 1.1127915382385254,
      "learning_rate": 8.894090111176128e-06,
      "loss": 0.1253,
      "step": 1455
    },
    {
      "epoch": 0.8300170551449687,
      "grad_norm": 1.1791824102401733,
      "learning_rate": 8.747805734347572e-06,
      "loss": 0.1483,
      "step": 1460
    },
    {
      "epoch": 0.8328595793064241,
      "grad_norm": 0.18894731998443604,
      "learning_rate": 8.601521357519017e-06,
      "loss": 0.1312,
      "step": 1465
    },
    {
      "epoch": 0.8357021034678794,
      "grad_norm": 1.4228668212890625,
      "learning_rate": 8.455236980690464e-06,
      "loss": 0.2196,
      "step": 1470
    },
    {
      "epoch": 0.8385446276293349,
      "grad_norm": 0.12574969232082367,
      "learning_rate": 8.308952603861907e-06,
      "loss": 0.1206,
      "step": 1475
    },
    {
      "epoch": 0.8413871517907903,
      "grad_norm": 1.346328616142273,
      "learning_rate": 8.162668227033353e-06,
      "loss": 0.0748,
      "step": 1480
    },
    {
      "epoch": 0.8442296759522456,
      "grad_norm": 1.4152836799621582,
      "learning_rate": 8.0163838502048e-06,
      "loss": 0.1367,
      "step": 1485
    },
    {
      "epoch": 0.847072200113701,
      "grad_norm": 1.2567951679229736,
      "learning_rate": 7.870099473376245e-06,
      "loss": 0.2277,
      "step": 1490
    },
    {
      "epoch": 0.8499147242751564,
      "grad_norm": 1.04912269115448,
      "learning_rate": 7.723815096547688e-06,
      "loss": 0.1316,
      "step": 1495
    },
    {
      "epoch": 0.8527572484366117,
      "grad_norm": 1.2805023193359375,
      "learning_rate": 7.577530719719135e-06,
      "loss": 0.1283,
      "step": 1500
    },
    {
      "epoch": 0.8555997725980671,
      "grad_norm": 0.1679772287607193,
      "learning_rate": 7.43124634289058e-06,
      "loss": 0.0408,
      "step": 1505
    },
    {
      "epoch": 0.8584422967595224,
      "grad_norm": 1.1892435550689697,
      "learning_rate": 7.284961966062025e-06,
      "loss": 0.1871,
      "step": 1510
    },
    {
      "epoch": 0.8612848209209778,
      "grad_norm": 0.8736540675163269,
      "learning_rate": 7.138677589233469e-06,
      "loss": 0.1544,
      "step": 1515
    },
    {
      "epoch": 0.8641273450824332,
      "grad_norm": 0.21172276139259338,
      "learning_rate": 6.992393212404915e-06,
      "loss": 0.1024,
      "step": 1520
    },
    {
      "epoch": 0.8669698692438885,
      "grad_norm": 0.23325829207897186,
      "learning_rate": 6.8461088355763606e-06,
      "loss": 0.1057,
      "step": 1525
    },
    {
      "epoch": 0.869812393405344,
      "grad_norm": 0.19075581431388855,
      "learning_rate": 6.699824458747806e-06,
      "loss": 0.0581,
      "step": 1530
    },
    {
      "epoch": 0.8726549175667994,
      "grad_norm": 0.9972493052482605,
      "learning_rate": 6.553540081919252e-06,
      "loss": 0.2142,
      "step": 1535
    },
    {
      "epoch": 0.8754974417282547,
      "grad_norm": 0.13229086995124817,
      "learning_rate": 6.407255705090696e-06,
      "loss": 0.0447,
      "step": 1540
    },
    {
      "epoch": 0.8783399658897101,
      "grad_norm": 0.14191769063472748,
      "learning_rate": 6.2609713282621415e-06,
      "loss": 0.0438,
      "step": 1545
    },
    {
      "epoch": 0.8811824900511654,
      "grad_norm": 0.16351528465747833,
      "learning_rate": 6.1146869514335876e-06,
      "loss": 0.0794,
      "step": 1550
    },
    {
      "epoch": 0.8840250142126208,
      "grad_norm": 0.10976435244083405,
      "learning_rate": 5.968402574605032e-06,
      "loss": 0.0873,
      "step": 1555
    },
    {
      "epoch": 0.8868675383740762,
      "grad_norm": 1.3774898052215576,
      "learning_rate": 5.822118197776478e-06,
      "loss": 0.2159,
      "step": 1560
    },
    {
      "epoch": 0.8897100625355315,
      "grad_norm": 1.1756492853164673,
      "learning_rate": 5.675833820947923e-06,
      "loss": 0.1276,
      "step": 1565
    },
    {
      "epoch": 0.8925525866969869,
      "grad_norm": 0.14843063056468964,
      "learning_rate": 5.5295494441193685e-06,
      "loss": 0.0012,
      "step": 1570
    },
    {
      "epoch": 0.8953951108584423,
      "grad_norm": 0.10198743641376495,
      "learning_rate": 5.383265067290814e-06,
      "loss": 0.0017,
      "step": 1575
    },
    {
      "epoch": 0.8982376350198976,
      "grad_norm": 0.17565655708312988,
      "learning_rate": 5.236980690462259e-06,
      "loss": 0.0596,
      "step": 1580
    },
    {
      "epoch": 0.9010801591813531,
      "grad_norm": 0.15075689554214478,
      "learning_rate": 5.090696313633704e-06,
      "loss": 0.0912,
      "step": 1585
    },
    {
      "epoch": 0.9039226833428085,
      "grad_norm": 1.564666748046875,
      "learning_rate": 4.9444119368051494e-06,
      "loss": 0.1761,
      "step": 1590
    },
    {
      "epoch": 0.9067652075042638,
      "grad_norm": 0.9449717998504639,
      "learning_rate": 4.798127559976595e-06,
      "loss": 0.0635,
      "step": 1595
    },
    {
      "epoch": 0.9096077316657192,
      "grad_norm": 1.4406360387802124,
      "learning_rate": 4.65184318314804e-06,
      "loss": 0.1046,
      "step": 1600
    },
    {
      "epoch": 0.9124502558271745,
      "grad_norm": 1.152227759361267,
      "learning_rate": 4.505558806319485e-06,
      "loss": 0.0331,
      "step": 1605
    },
    {
      "epoch": 0.9152927799886299,
      "grad_norm": 1.8717178106307983,
      "learning_rate": 4.35927442949093e-06,
      "loss": 0.2669,
      "step": 1610
    },
    {
      "epoch": 0.9181353041500853,
      "grad_norm": 1.329293131828308,
      "learning_rate": 4.212990052662376e-06,
      "loss": 0.1582,
      "step": 1615
    },
    {
      "epoch": 0.9209778283115406,
      "grad_norm": 1.4910520315170288,
      "learning_rate": 4.066705675833822e-06,
      "loss": 0.0753,
      "step": 1620
    },
    {
      "epoch": 0.923820352472996,
      "grad_norm": 1.324929118156433,
      "learning_rate": 3.920421299005266e-06,
      "loss": 0.0479,
      "step": 1625
    },
    {
      "epoch": 0.9266628766344513,
      "grad_norm": 0.14494973421096802,
      "learning_rate": 3.7741369221767117e-06,
      "loss": 0.0857,
      "step": 1630
    },
    {
      "epoch": 0.9295054007959067,
      "grad_norm": 0.9247064590454102,
      "learning_rate": 3.6278525453481574e-06,
      "loss": 0.1616,
      "step": 1635
    },
    {
      "epoch": 0.9323479249573622,
      "grad_norm": 0.14186444878578186,
      "learning_rate": 3.481568168519602e-06,
      "loss": 0.0987,
      "step": 1640
    },
    {
      "epoch": 0.9351904491188175,
      "grad_norm": 0.1073276475071907,
      "learning_rate": 3.3352837916910474e-06,
      "loss": 0.137,
      "step": 1645
    },
    {
      "epoch": 0.9380329732802729,
      "grad_norm": 0.16843780875205994,
      "learning_rate": 3.188999414862493e-06,
      "loss": 0.0401,
      "step": 1650
    },
    {
      "epoch": 0.9408754974417283,
      "grad_norm": 0.08712203055620193,
      "learning_rate": 3.042715038033938e-06,
      "loss": 0.0774,
      "step": 1655
    },
    {
      "epoch": 0.9437180216031836,
      "grad_norm": 1.3340837955474854,
      "learning_rate": 2.8964306612053835e-06,
      "loss": 0.121,
      "step": 1660
    },
    {
      "epoch": 0.946560545764639,
      "grad_norm": 1.4954633712768555,
      "learning_rate": 2.7501462843768288e-06,
      "loss": 0.1155,
      "step": 1665
    },
    {
      "epoch": 0.9494030699260944,
      "grad_norm": 0.16229240596294403,
      "learning_rate": 2.603861907548274e-06,
      "loss": 0.1186,
      "step": 1670
    },
    {
      "epoch": 0.9522455940875497,
      "grad_norm": 0.15518483519554138,
      "learning_rate": 2.4575775307197192e-06,
      "loss": 0.2154,
      "step": 1675
    },
    {
      "epoch": 0.9550881182490051,
      "grad_norm": 0.14921598136425018,
      "learning_rate": 2.3112931538911645e-06,
      "loss": 0.0233,
      "step": 1680
    },
    {
      "epoch": 0.9579306424104604,
      "grad_norm": 0.12698997557163239,
      "learning_rate": 2.1650087770626097e-06,
      "loss": 0.1259,
      "step": 1685
    },
    {
      "epoch": 0.9607731665719159,
      "grad_norm": 1.1809191703796387,
      "learning_rate": 2.0187244002340554e-06,
      "loss": 0.2082,
      "step": 1690
    },
    {
      "epoch": 0.9636156907333713,
      "grad_norm": 1.006674885749817,
      "learning_rate": 1.8724400234055004e-06,
      "loss": 0.2554,
      "step": 1695
    },
    {
      "epoch": 0.9664582148948266,
      "grad_norm": 0.20518171787261963,
      "learning_rate": 1.7261556465769456e-06,
      "loss": 0.1495,
      "step": 1700
    },
    {
      "epoch": 0.969300739056282,
      "grad_norm": 1.3878531455993652,
      "learning_rate": 1.579871269748391e-06,
      "loss": 0.0852,
      "step": 1705
    },
    {
      "epoch": 0.9721432632177374,
      "grad_norm": 1.5231895446777344,
      "learning_rate": 1.4335868929198363e-06,
      "loss": 0.1536,
      "step": 1710
    },
    {
      "epoch": 0.9749857873791927,
      "grad_norm": 1.3596835136413574,
      "learning_rate": 1.2873025160912815e-06,
      "loss": 0.0873,
      "step": 1715
    },
    {
      "epoch": 0.9778283115406481,
      "grad_norm": 0.12560272216796875,
      "learning_rate": 1.1410181392627268e-06,
      "loss": 0.0848,
      "step": 1720
    },
    {
      "epoch": 0.9806708357021034,
      "grad_norm": 1.2364192008972168,
      "learning_rate": 9.94733762434172e-07,
      "loss": 0.0944,
      "step": 1725
    },
    {
      "epoch": 0.9835133598635588,
      "grad_norm": 0.19401894509792328,
      "learning_rate": 8.484493856056173e-07,
      "loss": 0.036,
      "step": 1730
    },
    {
      "epoch": 0.9863558840250142,
      "grad_norm": 1.1719942092895508,
      "learning_rate": 7.021650087770626e-07,
      "loss": 0.0855,
      "step": 1735
    },
    {
      "epoch": 0.9891984081864695,
      "grad_norm": 0.21661825478076935,
      "learning_rate": 5.55880631948508e-07,
      "loss": 0.1624,
      "step": 1740
    },
    {
      "epoch": 0.992040932347925,
      "grad_norm": 0.8853688836097717,
      "learning_rate": 4.0959625511995324e-07,
      "loss": 0.0661,
      "step": 1745
    },
    {
      "epoch": 0.9948834565093804,
      "grad_norm": 0.9664365649223328,
      "learning_rate": 2.633118782913985e-07,
      "loss": 0.095,
      "step": 1750
    },
    {
      "epoch": 0.9977259806708357,
      "grad_norm": 1.0571852922439575,
      "learning_rate": 1.1702750146284377e-07,
      "loss": 0.2044,
      "step": 1755
    }
  ],
  "logging_steps": 5,
  "max_steps": 1759,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 229810492145664.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
